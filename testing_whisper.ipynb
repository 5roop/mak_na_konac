{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peterr/mambaforge/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/peterr/mambaforge/lib/python3.9/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/home/peterr/mambaforge/lib/python3.9/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/home/peterr/mambaforge/lib/python3.9/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/home/peterr/mambaforge/lib/python3.9/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/home/peterr/mambaforge/lib/python3.9/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/home/peterr/mambaforge/lib/python3.9/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/home/peterr/mambaforge/lib/python3.9/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Soundfile is either not in the correct format or is malformed. Ensure that the soundfile has a valid audio file extension (e.g. wav, flac or mp3) and is not corrupted. If reading from a remote URL, ensure that the URL is the full address to **download** the audio file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/cache/peterr/mak_na_konac/testing_whisper.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2/cache/peterr/mak_na_konac/testing_whisper.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m transcripts \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2/cache/peterr/mak_na_konac/testing_whisper.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m files_to_process:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgpu2/cache/peterr/mak_na_konac/testing_whisper.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m     t \u001b[39m=\u001b[39m pipe(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2/cache/peterr/mak_na_konac/testing_whisper.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m         file,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2/cache/peterr/mak_na_konac/testing_whisper.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m         generate_kwargs\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mlanguage\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mserbian\u001b[39;49m\u001b[39m\"\u001b[39;49m},\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2/cache/peterr/mak_na_konac/testing_whisper.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2/cache/peterr/mak_na_konac/testing_whisper.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m     transcripts\u001b[39m.\u001b[39mappend(t)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2/cache/peterr/mak_na_konac/testing_whisper.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m# result = pipe(\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2/cache/peterr/mak_na_konac/testing_whisper.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m#     KeyDataset(ds, \"audio\"),\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2/cache/peterr/mak_na_konac/testing_whisper.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m     \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2/cache/peterr/mak_na_konac/testing_whisper.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2/cache/peterr/mak_na_konac/testing_whisper.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# pd.DataFrame({\"file\": files_to_process, \"transcript\": transcripts})\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/transformers/pipelines/automatic_speech_recognition.py:357\u001b[0m, in \u001b[0;36mAutomaticSpeechRecognitionPipeline.__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    295\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    296\u001b[0m     inputs: Union[np\u001b[39m.\u001b[39mndarray, \u001b[39mbytes\u001b[39m, \u001b[39mstr\u001b[39m],\n\u001b[1;32m    297\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    298\u001b[0m ):\n\u001b[1;32m    299\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[39m    Transcribe the audio sequence(s) given as inputs to text. See the [`AutomaticSpeechRecognitionPipeline`]\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[39m    documentation for more information.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39m                `\"\".join(chunk[\"text\"] for chunk in output[\"chunks\"])`.\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 357\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/transformers/pipelines/base.py:1132\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1131\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ChunkPipeline):\n\u001b[0;32m-> 1132\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\n\u001b[1;32m   1133\u001b[0m         \u001b[39miter\u001b[39;49m(\n\u001b[1;32m   1134\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_iterator(\n\u001b[1;32m   1135\u001b[0m                 [inputs], num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1136\u001b[0m             )\n\u001b[1;32m   1137\u001b[0m         )\n\u001b[1;32m   1138\u001b[0m     )\n\u001b[1;32m   1139\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[39m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[1;32m    125\u001b[0m processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(item, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[39m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/transformers/pipelines/pt_utils.py:266\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[39mreturn\u001b[39;00m accumulator\n\u001b[1;32m    265\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_last:\n\u001b[0;32m--> 266\u001b[0m     processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(\u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[1;32m    267\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed, torch\u001b[39m.\u001b[39mTensor):\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:32\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m possibly_batched_index:\n\u001b[1;32m     31\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m         data\u001b[39m.\u001b[39mappend(\u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_iter))\n\u001b[1;32m     33\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mended \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/transformers/pipelines/pt_utils.py:183\u001b[0m, in \u001b[0;36mPipelineChunkIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubiterator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(\u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[1;32m    181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     \u001b[39m# Try to return next item\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m     processed \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubiterator)\n\u001b[1;32m    184\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[39m# When a preprocess iterator ends, we can start lookig at the next item\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     \u001b[39m# ChunkIterator will keep feeding until ALL elements of iterator\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[39m# Another way to look at it, is we're basically flattening lists of lists\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     \u001b[39m# into a single list, but with generators\u001b[39;00m\n\u001b[1;32m    191\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubiterator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(\u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/transformers/pipelines/automatic_speech_recognition.py:434\u001b[0m, in \u001b[0;36mAutomaticSpeechRecognitionPipeline.preprocess\u001b[0;34m(self, inputs, chunk_length_s, stride_length_s)\u001b[0m\n\u001b[1;32m    431\u001b[0m             inputs \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[1;32m    433\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, \u001b[39mbytes\u001b[39m):\n\u001b[0;32m--> 434\u001b[0m     inputs \u001b[39m=\u001b[39m ffmpeg_read(inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_extractor\u001b[39m.\u001b[39;49msampling_rate)\n\u001b[1;32m    436\u001b[0m stride \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    437\u001b[0m extra \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/transformers/pipelines/audio_utils.py:41\u001b[0m, in \u001b[0;36mffmpeg_read\u001b[0;34m(bpayload, sampling_rate)\u001b[0m\n\u001b[1;32m     39\u001b[0m audio \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfrombuffer(out_bytes, np\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     40\u001b[0m \u001b[39mif\u001b[39;00m audio\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     42\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSoundfile is either not in the correct format or is malformed. Ensure that the soundfile has \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39ma valid audio file extension (e.g. wav, flac or mp3) and is not corrupted. If reading from a remote \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     44\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mURL, ensure that the URL is the full address to **download** the audio file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m     )\n\u001b[1;32m     46\u001b[0m \u001b[39mreturn\u001b[39;00m audio\n",
      "\u001b[0;31mValueError\u001b[0m: Soundfile is either not in the correct format or is malformed. Ensure that the soundfile has a valid audio file extension (e.g. wav, flac or mp3) and is not corrupted. If reading from a remote URL, ensure that the URL is the full address to **download** the audio file."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "device = \"cuda:2\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "\n",
    "# result = pipe(\"data/02_Južne_vesti/160121/160121.wav\",\n",
    "#               generate_kwargs={\"language\": \"serbian\"})\n",
    "\n",
    "\n",
    "files_to_process = ['data/02_Južne_vesti_asr/161226/segments/T129__T130.wav', 'data/02_Južne_vesti_asr/161226/segments/T120__T121.wav', 'data/02_Južne_vesti_asr/161226/segments/T109__T110.wav', 'data/02_Južne_vesti_asr/161226/segments/T60__T61.wav', 'data/02_Južne_vesti_asr/161226/segments/T15__T16.wav', 'data/02_Južne_vesti_asr/161226/segments/T135__T136.wav', 'data/02_Južne_vesti_asr/161226/segments/T32__T33.wav', 'data/02_Južne_vesti_asr/161226/segments/T9__T10.wav', 'data/02_Južne_vesti_asr/161226/segments/T54__T55.wav', 'data/02_Južne_vesti_asr/161226/segments/T100__T101.wav', 'data/02_Južne_vesti_asr/161226/segments/T49__T50.wav', 'data/02_Južne_vesti_asr/161226/segments/T55__T56.wav', 'data/02_Južne_vesti_asr/161226/segments/T124__T125.wav', 'data/02_Južne_vesti_asr/161226/segments/T131__T132.wav', 'data/02_Južne_vesti_asr/161226/segments/T125__T126.wav', 'data/02_Južne_vesti_asr/161226/segments/T127__T128.wav', 'data/02_Južne_vesti_asr/161226/segments/T2__T0.wav', 'data/02_Južne_vesti_asr/161226/segments/T90__T91.wav', 'data/02_Južne_vesti_asr/161226/segments/T70__T71.wav', 'data/02_Južne_vesti_asr/161226/segments/T12__T13.wav', 'data/02_Južne_vesti_asr/161226/segments/T56__T57.wav', 'data/02_Južne_vesti_asr/161226/segments/T61__T62.wav', 'data/02_Južne_vesti_asr/161226/segments/T48__T49.wav', 'data/02_Južne_vesti_asr/161226/segments/T42__T43.wav', 'data/02_Južne_vesti_asr/161226/segments/T119__T120.wav', 'data/02_Južne_vesti_asr/161226/segments/T45__T46.wav', 'data/02_Južne_vesti_asr/161226/segments/T5__T6.wav', 'data/02_Južne_vesti_asr/161226/segments/T23__T24.wav', 'data/02_Južne_vesti_asr/161226/segments/T69__T70.wav', 'data/02_Južne_vesti_asr/161226/segments/T80__T81.wav', 'data/02_Južne_vesti_asr/161226/segments/T88__T89.wav', 'data/02_Južne_vesti_asr/161226/segments/T53__T54.wav', 'data/02_Južne_vesti_asr/161226/segments/T51__T52.wav', 'data/02_Južne_vesti_asr/161226/segments/T104__T105.wav', 'data/02_Južne_vesti_asr/161226/segments/T87__T88.wav', 'data/02_Južne_vesti_asr/161226/segments/T21__T22.wav', 'data/02_Južne_vesti_asr/161226/segments/T128__T129.wav', 'data/02_Južne_vesti_asr/161226/segments/T30__T31.wav', 'data/02_Južne_vesti_asr/161226/segments/T36__T37.wav', 'data/02_Južne_vesti_asr/161226/segments/T139__T140.wav', 'data/02_Južne_vesti_asr/161226/segments/T107__T108.wav', 'data/02_Južne_vesti_asr/161226/segments/T65__T66.wav', 'data/02_Južne_vesti_asr/161226/segments/T133__T134.wav', 'data/02_Južne_vesti_asr/161226/segments/T122__T123.wav', 'data/02_Južne_vesti_asr/161226/segments/T66__T67.wav', 'data/02_Južne_vesti_asr/161226/segments/T108__T109.wav', 'data/02_Južne_vesti_asr/161226/segments/T40__T41.wav', 'data/02_Južne_vesti_asr/161226/segments/T123__T124.wav', 'data/02_Južne_vesti_asr/161226/segments/T110__T111.wav', 'data/02_Južne_vesti_asr/161226/segments/T73__T74.wav', 'data/02_Južne_vesti_asr/161226/segments/T84__T85.wav', 'data/02_Južne_vesti_asr/161226/segments/T121__T122.wav', 'data/02_Južne_vesti_asr/161226/segments/T19__T20.wav', 'data/02_Južne_vesti_asr/161226/segments/T11__T12.wav', 'data/02_Južne_vesti_asr/161226/segments/T118__T119.wav', 'data/02_Južne_vesti_asr/161226/segments/T115__T116.wav', 'data/02_Južne_vesti_asr/161226/segments/T4__T5.wav', 'data/02_Južne_vesti_asr/161226/segments/T34__T35.wav', 'data/02_Južne_vesti_asr/161226/segments/T140__T1.wav', 'data/02_Južne_vesti_asr/161226/segments/T82__T83.wav', 'data/02_Južne_vesti_asr/161226/segments/T3__T4.wav', 'data/02_Južne_vesti_asr/161226/segments/T58__T59.wav', 'data/02_Južne_vesti_asr/161226/segments/T47__T48.wav', 'data/02_Južne_vesti_asr/161226/segments/T68__T69.wav', 'data/02_Južne_vesti_asr/161226/segments/T76__T77.wav', 'data/02_Južne_vesti_asr/161226/segments/T27__T28.wav', 'data/02_Južne_vesti_asr/161226/segments/T81__T82.wav', 'data/02_Južne_vesti_asr/161226/segments/T114__T115.wav', 'data/02_Južne_vesti_asr/161226/segments/T17__T18.wav', 'data/02_Južne_vesti_asr/161226/segments/T59__T60.wav', 'data/02_Južne_vesti_asr/161226/segments/T130__T131.wav', 'data/02_Južne_vesti_asr/161226/segments/T22__T23.wav', 'data/02_Južne_vesti_asr/161226/segments/T64__T65.wav', 'data/02_Južne_vesti_asr/161226/segments/T91__T92.wav', 'data/02_Južne_vesti_asr/161226/segments/T103__T104.wav', 'data/02_Južne_vesti_asr/161226/segments/T10__T11.wav', 'data/02_Južne_vesti_asr/161226/segments/T97__T98.wav', 'data/02_Južne_vesti_asr/161226/segments/T14__T15.wav', 'data/02_Južne_vesti_asr/161226/segments/T31__T32.wav', 'data/02_Južne_vesti_asr/161226/segments/T71__T72.wav', 'data/02_Južne_vesti_asr/161226/segments/T111__T112.wav', 'data/02_Južne_vesti_asr/161226/segments/T25__T26.wav', 'data/02_Južne_vesti_asr/161226/segments/T7__T8.wav', 'data/02_Južne_vesti_asr/161226/segments/T101__T102.wav', 'data/02_Južne_vesti_asr/161226/segments/T85__T86.wav', 'data/02_Južne_vesti_asr/161226/segments/T20__T21.wav', 'data/02_Južne_vesti_asr/161226/segments/T105__T106.wav', 'data/02_Južne_vesti_asr/161226/segments/T95__T96.wav', 'data/02_Južne_vesti_asr/161226/segments/T24__T25.wav', 'data/02_Južne_vesti_asr/161226/segments/T52__T53.wav', 'data/02_Južne_vesti_asr/161226/segments/T89__T90.wav', 'data/02_Južne_vesti_asr/161226/segments/T137__T138.wav', 'data/02_Južne_vesti_asr/161226/segments/T74__T75.wav', 'data/02_Južne_vesti_asr/161226/segments/T13__T14.wav', 'data/02_Južne_vesti_asr/161226/segments/T106__T107.wav', 'data/02_Južne_vesti_asr/161226/segments/T134__T135.wav', 'data/02_Južne_vesti_asr/161226/segments/T44__T45.wav', 'data/02_Južne_vesti_asr/161226/segments/T92__T93.wav', 'data/02_Južne_vesti_asr/161226/segments/T112__T113.wav', 'data/02_Južne_vesti_asr/161226/segments/T28__T29.wav', 'data/02_Južne_vesti_asr/161226/segments/T39__T40.wav', 'data/02_Južne_vesti_asr/161226/segments/T50__T51.wav', 'data/02_Južne_vesti_asr/161226/segments/T75__T76.wav', 'data/02_Južne_vesti_asr/161226/segments/T62__T63.wav', 'data/02_Južne_vesti_asr/161226/segments/T6__T7.wav', 'data/02_Južne_vesti_asr/161226/segments/T79__T80.wav', 'data/02_Južne_vesti_asr/161226/segments/T117__T118.wav', 'data/02_Južne_vesti_asr/161226/segments/T126__T127.wav', 'data/02_Južne_vesti_asr/161226/segments/T41__T42.wav', 'data/02_Južne_vesti_asr/161226/segments/T18__T19.wav', 'data/02_Južne_vesti_asr/161226/segments/T0__T3.wav', 'data/02_Južne_vesti_asr/161226/segments/T138__T139.wav', 'data/02_Južne_vesti_asr/161226/segments/T132__T133.wav', 'data/02_Južne_vesti_asr/161226/segments/T113__T114.wav', 'data/02_Južne_vesti_asr/161226/segments/T63__T64.wav', 'data/02_Južne_vesti_asr/161226/segments/T26__T27.wav', 'data/02_Južne_vesti_asr/161226/segments/T78__T79.wav', 'data/02_Južne_vesti_asr/161226/segments/T67__T68.wav', 'data/02_Južne_vesti_asr/161226/segments/T29__T30.wav', 'data/02_Južne_vesti_asr/161226/segments/T116__T117.wav', 'data/02_Južne_vesti_asr/161226/segments/T83__T84.wav', 'data/02_Južne_vesti_asr/161226/segments/T38__T39.wav', 'data/02_Južne_vesti_asr/161226/segments/T35__T36.wav', 'data/02_Južne_vesti_asr/161226/segments/T102__T103.wav', 'data/02_Južne_vesti_asr/161226/segments/T37__T38.wav', 'data/02_Južne_vesti_asr/161226/segments/T94__T95.wav', 'data/02_Južne_vesti_asr/161226/segments/T43__T44.wav', 'data/02_Južne_vesti_asr/161226/segments/T98__T99.wav', 'data/02_Južne_vesti_asr/161226/segments/T77__T78.wav', 'data/02_Južne_vesti_asr/161226/segments/T8__T9.wav', 'data/02_Južne_vesti_asr/161226/segments/T33__T34.wav', 'data/02_Južne_vesti_asr/161226/segments/T99__T100.wav', 'data/02_Južne_vesti_asr/161226/segments/T16__T17.wav', 'data/02_Južne_vesti_asr/161226/segments/T86__T87.wav', 'data/02_Južne_vesti_asr/161226/segments/T93__T94.wav', 'data/02_Južne_vesti_asr/161226/segments/T72__T73.wav', 'data/02_Južne_vesti_asr/161226/segments/T136__T137.wav', 'data/02_Južne_vesti_asr/161226/segments/T96__T97.wav', 'data/02_Južne_vesti_asr/161226/segments/T57__T58.wav', 'data/02_Južne_vesti_asr/161226/segments/T46__T47.wav']\n",
    "from datasets import Dataset, Audio\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "ds = Dataset.from_dict({\"audio\": files_to_process}).cast_column(\"audio\", Audio(sampling_rate=16000, mono=True))\n",
    "transcripts = []\n",
    "for file in files_to_process:\n",
    "    t = pipe(\n",
    "        file,\n",
    "        generate_kwargs={\"language\": \"serbian\"},\n",
    "    )\n",
    "    transcripts.append(t)\n",
    "\n",
    "# result = pipe(\n",
    "#     KeyDataset(ds, \"audio\"),\n",
    "    \n",
    "# )\n",
    "# transcripts = [i.get(\"text\") for i in result]\n",
    "# # transcripts = [pipe(file, generate_kwargs={\"language\":\"serbian\"}).get(\"text\") for file in files_to_process]\n",
    "# import pandas as pd\n",
    "\n",
    "# pd.DataFrame({\"file\": files_to_process, \"transcript\": transcripts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input File     : 'data/02_Južne_vesti_asr/161226/segments/T2__T0.wav'\n",
      "Channels       : 1\n",
      "Sample Rate    : 16000\n",
      "Precision      : 16-bit\n",
      "Sample Encoding: 16-bit Signed Integer PCM\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!soxi $file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any([\" \" in i for i in files_to_process])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
